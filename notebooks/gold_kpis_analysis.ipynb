{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff7f0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, avg, max as spark_max, min as spark_min, stddev, when, desc, round as spark_round\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from minio import Minio\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c14fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar SparkSession\n",
    "try:\n",
    "    sc = SparkContext.getOrCreate()\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass\n",
    "import time\n",
    "time.sleep(1)\n",
    "conf = SparkConf().setAppName(\"GenerarKPIs\").setMaster(\"local[*]\").set(\"spark.driver.bindAddress\", \"127.0.0.1\").set(\"spark.driver.host\", \"127.0.0.1\")\n",
    "try:\n",
    "    sc = SparkContext(conf=conf)\n",
    "    spark = SparkSession(sc)\n",
    "except:\n",
    "    spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "print(\"âœ… Spark iniciado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c03e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConfiguraciÃ³n MinIO\n",
    "MINIO_ENDPOINT = os.environ.get(\"MINIO_ENDPOINT\", \"localhost:9000\")\n",
    "MINIO_ACCESS_KEY = os.environ.get(\"MINIO_ACCESS_KEY\", \"minioadmin\")\n",
    "MINIO_SECRET_KEY = os.environ.get(\"MINIO_SECRET_KEY\", \"minioadmin\")\n",
    "MINIO_BUCKET_SILVER = \"proyecto-silver\"\n",
    "MINIO_BUCKET_GOLD = \"proyecto-gold\"\n",
    "\n",
    "minio_client = Minio(MINIO_ENDPOINT, access_key=MINIO_ACCESS_KEY, secret_key=MINIO_SECRET_KEY, secure=False)\n",
    "print(\"âœ… MinIO conectado\")\n",
    "\n",
    "# Crear bucket Gold si no existe\n",
    "try:\n",
    "    minio_client.make_bucket(MINIO_BUCKET_GOLD)\n",
    "    print(f'âœ… Bucket {MINIO_BUCKET_GOLD} creado')\n",
    "except:\n",
    "    print(f'âœ… Bucket {MINIO_BUCKET_GOLD} ya existe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7de619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos de Silver\n",
    "print(\"\\nğŸ“¥ CARGANDO DATOS DE SILVER...\")\n",
    "\n",
    "try:\n",
    "    print(\"Buscando archivos Silver...\")\n",
    "    objects = minio_client.list_objects(MINIO_BUCKET_SILVER, recursive=True)\n",
    "    archivos_parquet = [obj.object_name for obj in objects if obj.object_name.endswith(\".parquet\")]\n",
    "    \n",
    "    if archivos_parquet:\n",
    "        dfs = []\n",
    "        for archivo in sorted(archivos_parquet):\n",
    "            temp_dir = tempfile.gettempdir()\n",
    "            temp_file = os.path.join(temp_dir, archivo.split(\"/\")[-1])\n",
    "            minio_client.fget_object(MINIO_BUCKET_SILVER, archivo, temp_file)\n",
    "            df_temp = spark.read.parquet(temp_file)\n",
    "            dfs.append(df_temp)\n",
    "            print(f\"  Cargado: {archivo}\")\n",
    "        \n",
    "        from functools import reduce\n",
    "        spark_df = reduce(lambda x, y: x.union(y), dfs)\n",
    "        print(f\"\\nâœ… Datos consolidados: {spark_df.count()} registros\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Sin archivos en Silver\")\n",
    "        spark_df = spark.createDataFrame([], \"id INT, temperature DOUBLE, humidity DOUBLE\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Error: {e}\")\n",
    "    spark_df = spark.createDataFrame([], \"id INT, temperature DOUBLE, humidity DOUBLE\")\n",
    "\n",
    "print(f\"\\nğŸ“Š DataFrame: {spark_df.count()} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a0a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar KPIs\n",
    "print(\"\\nğŸ“Š GENERANDO KPIs...\")\n",
    "\n",
    "if spark_df.count() > 0:\n",
    "    # Calcular KPIs generales\n",
    "    kpis = {}\n",
    "    \n",
    "    kpis['total_readings'] = spark_df.count()\n",
    "    kpis['unique_sensors'] = spark_df.select('sensor_id').distinct().count() if 'sensor_id' in spark_df.columns else 0\n",
    "    \n",
    "    # KPIs de temperatura\n",
    "    if 'temperature' in spark_df.columns:\n",
    "        temp_stats = spark_df.select(\n",
    "            avg('temperature').alias('temp_avg'),\n",
    "            spark_max('temperature').alias('temp_max'),\n",
    "            spark_min('temperature').alias('temp_min'),\n",
    "            stddev('temperature').alias('temp_std')\n",
    "        ).collect()[0]\n",
    "        \n",
    "        kpis['temperature_avg'] = temp_stats['temp_avg']\n",
    "        kpis['temperature_max'] = temp_stats['temp_max']\n",
    "        kpis['temperature_min'] = temp_stats['temp_min']\n",
    "        kpis['temperature_std'] = temp_stats['temp_std']\n",
    "    \n",
    "    # KPIs de humedad\n",
    "    if 'humidity' in spark_df.columns:\n",
    "        humidity_stats = spark_df.select(\n",
    "            avg('humidity').alias('humidity_avg'),\n",
    "            spark_max('humidity').alias('humidity_max'),\n",
    "            spark_min('humidity').alias('humidity_min')\n",
    "        ).collect()[0]\n",
    "        \n",
    "        kpis['humidity_avg'] = humidity_stats['humidity_avg']\n",
    "        kpis['humidity_max'] = humidity_stats['humidity_max']\n",
    "        kpis['humidity_min'] = humidity_stats['humidity_min']\n",
    "    \n",
    "    # KPIs de PM2.5\n",
    "    if 'pm25' in spark_df.columns:\n",
    "        pm25_stats = spark_df.select(\n",
    "            avg('pm25').alias('pm25_avg'),\n",
    "            spark_max('pm25').alias('pm25_max')\n",
    "        ).collect()[0]\n",
    "        \n",
    "        kpis['pm25_avg'] = pm25_stats['pm25_avg']\n",
    "        kpis['pm25_max'] = pm25_stats['pm25_max']\n",
    "        \n",
    "        # ClasificaciÃ³n de calidad del aire\n",
    "        pm25_val = pm25_stats['pm25_avg']\n",
    "        if pm25_val > 150:\n",
    "            kpis['air_quality_category'] = 'Peligroso'\n",
    "        elif pm25_val > 100:\n",
    "            kpis['air_quality_category'] = 'Muy insalubre'\n",
    "        elif pm25_val > 50:\n",
    "            kpis['air_quality_category'] = 'Insalubre'\n",
    "        elif pm25_val > 25:\n",
    "            kpis['air_quality_category'] = 'Moderado'\n",
    "        else:\n",
    "            kpis['air_quality_category'] = 'Bueno'\n",
    "    \n",
    "    # KPIs de presiÃ³n\n",
    "    if 'pressure' in spark_df.columns:\n",
    "        pressure_stats = spark_df.select(\n",
    "            avg('pressure').alias('pressure_avg'),\n",
    "            spark_max('pressure').alias('pressure_max'),\n",
    "            spark_min('pressure').alias('pressure_min')\n",
    "        ).collect()[0]\n",
    "        \n",
    "        kpis['pressure_avg'] = pressure_stats['pressure_avg']\n",
    "        kpis['pressure_max'] = pressure_stats['pressure_max']\n",
    "        kpis['pressure_min'] = pressure_stats['pressure_min']\n",
    "    \n",
    "    # Generar alertas\n",
    "    alerts = {}\n",
    "    \n",
    "    if 'temperature' in spark_df.columns:\n",
    "        alerts['high_temperature'] = spark_df.filter(col('temperature') > 30).count()\n",
    "        alerts['low_temperature'] = spark_df.filter(col('temperature') < 5).count()\n",
    "    \n",
    "    if 'humidity' in spark_df.columns:\n",
    "        alerts['high_humidity'] = spark_df.filter(col('humidity') > 80).count()\n",
    "        alerts['low_humidity'] = spark_df.filter(col('humidity') < 20).count()\n",
    "    \n",
    "    kpis['alerts_json'] = str(alerts)\n",
    "    \n",
    "    print(f\"KPIs generados:\")\n",
    "    for key, value in kpis.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"   {key}: {value:.2f}\")\n",
    "        else:\n",
    "            print(f\"   {key}: {value}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No hay datos para generar KPIs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17aea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EstadÃ­sticas por sensor\n",
    "print(\"\\nğŸ“ˆ ESTADÃSTICAS POR SENSOR...\")\n",
    "\n",
    "if spark_df.count() > 0 and 'sensor_id' in spark_df.columns:\n",
    "    sensor_stats = spark_df.groupBy('sensor_id').agg(\n",
    "        count('*').alias('readings_count'),\n",
    "        avg('temperature').alias('temp_avg'),\n",
    "        spark_max('temperature').alias('temp_max'),\n",
    "        spark_min('temperature').alias('temp_min'),\n",
    "        avg('humidity').alias('humidity_avg')\n",
    "    ).orderBy(desc('readings_count'))\n",
    "    \n",
    "    print(\"\\nEstadÃ­sticas por sensor:\")\n",
    "    sensor_stats.show()\n",
    "    \n",
    "    # Convertir a DataFrame de Pandas para guardar\n",
    "    sensor_stats_pd = sensor_stats.toPandas()\n",
    "else:\n",
    "    print(\"âš ï¸ No hay datos de sensores para procesar\")\n",
    "    sensor_stats_pd = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbdeb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar KPIs en Gold\n",
    "print(\"\\nğŸ’¾ GUARDANDO KPIs EN GOLD...\")\n",
    "\n",
    "try:\n",
    "    import io\n",
    "    from pyspark.sql.types import TimestampType\n",
    "    \n",
    "    # Guardar KPIs como CSV\n",
    "    kpis_df = pd.DataFrame([kpis])\n",
    "    kpis_df['timestamp'] = datetime.now().isoformat()\n",
    "    kpis_df['generation_time'] = datetime.now()\n",
    "    \n",
    "    # Reordenar columnas\n",
    "    cols = ['timestamp', 'generation_time'] + [c for c in kpis_df.columns if c not in ['timestamp', 'generation_time']]\n",
    "    kpis_df = kpis_df[cols]\n",
    "    \n",
    "    kpis_csv = kpis_df.to_csv(index=False)\n",
    "    kpis_bytes = io.BytesIO(kpis_csv.encode('utf-8'))\n",
    "    \n",
    "    minio_client.put_object(\n",
    "        MINIO_BUCKET_GOLD,\n",
    "        \"sensor_kpis/kpis.csv\",\n",
    "        kpis_bytes,\n",
    "        length=len(kpis_csv.encode('utf-8')),\n",
    "        content_type=\"text/csv\"\n",
    "    )\n",
    "    print(\"âœ… KPIs guardados: sensor_kpis/kpis.csv\")\n",
    "    \n",
    "    # Guardar estadÃ­sticas por sensor\n",
    "    if not sensor_stats_pd.empty:\n",
    "        sensor_csv = sensor_stats_pd.to_csv(index=False)\n",
    "        sensor_bytes = io.BytesIO(sensor_csv.encode('utf-8'))\n",
    "        \n",
    "        minio_client.put_object(\n",
    "            MINIO_BUCKET_GOLD,\n",
    "            \"sensor_kpis/sensor_statistics.csv\",\n",
    "            sensor_bytes,\n",
    "            length=len(sensor_csv.encode('utf-8')),\n",
    "            content_type=\"text/csv\"\n",
    "        )\n",
    "        print(\"âœ… EstadÃ­sticas guardadas: sensor_kpis/sensor_statistics.csv\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error al guardar: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd38528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log de ejecuciÃ³n\n",
    "print(\"\\nğŸ“ GUARDANDO LOG DE EJECUCIÃ“N...\")\n",
    "\n",
    "try:\n",
    "    log_data = {\n",
    "        'script': 'gold_kpis_analysis_script',\n",
    "        'execution_time': datetime.now().isoformat(),\n",
    "        'kpis_generated': len(kpis),\n",
    "        'sensors_analyzed': kpis.get('unique_sensors', 0),\n",
    "        'output_files': ['kpis.parquet', 'sensor_statistics.parquet'],\n",
    "        'temperature_avg': kpis.get('temperature_avg', None),\n",
    "        'air_quality': kpis.get('air_quality_category', 'N/A'),\n",
    "        'total_sensors': kpis.get('unique_sensors', 0),\n",
    "        'status': 'completed'\n",
    "    }\n",
    "    \n",
    "    log_df = pd.DataFrame([log_data])\n",
    "    log_csv = log_df.to_csv(index=False)\n",
    "    log_bytes = io.BytesIO(log_csv.encode('utf-8'))\n",
    "    \n",
    "    minio_client.put_object(\n",
    "        MINIO_BUCKET_GOLD,\n",
    "        \"logs/execution_log.csv\",\n",
    "        log_bytes,\n",
    "        length=len(log_csv.encode('utf-8')),\n",
    "        content_type=\"text/csv\"\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Log guardado exitosamente\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar log: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c03c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen final\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… PROCESAMIENTO DE GOLD COMPLETADO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # Listar archivos en Gold\n",
    "    gold_files = minio_client.list_objects(MINIO_BUCKET_GOLD, recursive=True)\n",
    "    gold_files_list = [obj.object_name for obj in gold_files]\n",
    "    \n",
    "    print(f\"Procesamiento completado!\")\n",
    "    print(f\"Total archivos en Gold: {len(gold_files_list)}\")\n",
    "    print(f\"Temperatura promedio: {kpis.get('temperature_avg', 'N/A'):.2f}Â°C\" if isinstance(kpis.get('temperature_avg'), (int, float)) else f\"Temperatura promedio: N/A\")\n",
    "    print(f\"Calidad del aire: {kpis.get('air_quality_category', 'N/A')}\")\n",
    "    print(f\"Sensores Ãºnicos: {kpis.get('unique_sensors', 'N/A')}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error en resumen: {e}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67937a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar SparkContext\n",
    "print(\"\\nğŸ”š CERRANDO SESIÃ“N...\")\n",
    "\n",
    "try:\n",
    "    if 'spark' in locals():\n",
    "        spark.stop()\n",
    "        print(\"âœ… SesiÃ³n de Spark cerrada correctamente\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Error al cerrar Spark: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57af1e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen ejecutivo de KPIs\n",
    "if not kpis_df.empty and df_silver is not None:\n",
    "    print(\"=== RESUMEN EJECUTIVO ===\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"  ğŸ“ˆ REPORTE DE KPIs - SISTEMA DE MONITOREO DE SENSORES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Fecha y hora del reporte\n",
    "    report_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"ğŸ“… Generado: {report_time}\")\n",
    "    \n",
    "    # InformaciÃ³n general\n",
    "    total_readings = len(df_silver)\n",
    "    unique_sensors = df_silver['sensor_id'].nunique()\n",
    "    avg_quality = df_silver['data_quality_score'].mean()\n",
    "    \n",
    "    print(f\"\\nğŸ“Š MÃ‰TRICAS GENERALES:\")\n",
    "    print(f\"  â€¢ Total de lecturas procesadas: {total_readings:,}\")\n",
    "    print(f\"  â€¢ Sensores activos: {unique_sensors}\")\n",
    "    print(f\"  â€¢ Calidad promedio de datos: {avg_quality:.1f}/100\")\n",
    "    \n",
    "    # Condiciones ambientales promedio\n",
    "    avg_temp = df_silver['temperature'].mean()\n",
    "    avg_humidity = df_silver['humidity'].mean()\n",
    "    avg_pressure = df_silver['pressure'].mean()\n",
    "    \n",
    "    print(f\"\\nğŸŒ¡ï¸  CONDICIONES AMBIENTALES:\")\n",
    "    print(f\"  â€¢ Temperatura promedio: {avg_temp:.1f}Â°C\")\n",
    "    print(f\"  â€¢ Humedad promedio: {avg_humidity:.1f}%\")\n",
    "    print(f\"  â€¢ PresiÃ³n promedio: {avg_pressure:.1f} hPa\")\n",
    "    \n",
    "    # Alertas y anomalÃ­as\n",
    "    if 'total_anomalies' in locals():\n",
    "        print(f\"\\nâš ï¸  ALERTAS:\")\n",
    "        print(f\"  â€¢ AnomalÃ­as detectadas: {total_anomalies}\")\n",
    "        print(f\"  â€¢ Tasa de anomalÃ­as: {anomaly_rate:.2f}%\")\n",
    "    \n",
    "    # Estado del sistema\n",
    "    high_quality_readings = (df_silver['data_quality_score'] >= 90).sum()\n",
    "    quality_percentage = (high_quality_readings / total_readings) * 100\n",
    "    \n",
    "    print(f\"\\nâœ… ESTADO DEL SISTEMA:\")\n",
    "    print(f\"  â€¢ Lecturas de alta calidad: {high_quality_readings:,} ({quality_percentage:.1f}%)\")\n",
    "    \n",
    "    if quality_percentage >= 95:\n",
    "        system_status = \"ğŸŸ¢ EXCELENTE\"\n",
    "    elif quality_percentage >= 80:\n",
    "        system_status = \"ğŸŸ¡ BUENO\"\n",
    "    else:\n",
    "        system_status = \"ğŸ”´ REQUIERE ATENCIÃ“N\"\n",
    "    \n",
    "    print(f\"  â€¢ Estado general: {system_status}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“ KPIs disponibles para descarga en capa Gold\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be048e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar resultados\n",
    "if not kpis_df.empty:\n",
    "    print(\"=== EXPORTANDO RESULTADOS ===\")\n",
    "    \n",
    "    # Exportar KPIs para uso en otros mÃ³dulos\n",
    "    export_path = gold_layer.export_kpis_for_module()\n",
    "    \n",
    "    if export_path:\n",
    "        print(f\"âœ… KPIs exportados exitosamente\")\n",
    "        print(f\"ğŸ“ UbicaciÃ³n: {export_path}\")\n",
    "        print(f\"ğŸ“Š MÃ©tricas incluidas: {len(kpis_df)}\")\n",
    "        \n",
    "        # Mostrar resumen de archivos en Gold\n",
    "        gold_files_updated = minio_client.list_objects(Config.GOLD_PATH)\n",
    "        export_files = [f for f in gold_files_updated if 'export' in f]\n",
    "        \n",
    "        print(f\"\\nğŸ“‚ Archivos de exportaciÃ³n disponibles: {len(export_files)}\")\n",
    "        for export_file in export_files[-3:]:  # Mostrar Ãºltimos 3\n",
    "            print(f\"  â€¢ {export_file}\")\n",
    "            \n",
    "    else:\n",
    "        print(\"âŒ Error al exportar KPIs\")\n",
    "\n",
    "# InformaciÃ³n de acceso a los datos\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“‹ INFORMACIÃ“N DE ACCESO A DATOS:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"ğŸ—‚ï¸  Bucket MinIO: {Config.MINIO_BUCKET}\")\n",
    "print(f\"ğŸ“ Ruta Gold: {Config.GOLD_PATH}\")\n",
    "print(f\"ğŸŒ MinIO Console: http://{Config.MINIO_ENDPOINT.replace(':9000', ':9090')}\")\n",
    "print(f\"ğŸ‘¤ Usuario: {Config.MINIO_ACCESS_KEY}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6405abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar todos los KPIs en capa Gold (archivos Ãºnicos que se sobrescriben)\n",
    "print(\"=== GUARDANDO EN CAPA GOLD (ARCHIVOS ÃšNICOS) ===\")\n",
    "\n",
    "# Crear un diccionario con todos los KPIs calculados\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now()\n",
    "\n",
    "kpis_data = {\n",
    "    'timestamp': timestamp.isoformat(),\n",
    "    'generation_time': timestamp,\n",
    "    'temperature_avg': float(temperature_avg),\n",
    "    'temperature_max': float(temperature_max),\n",
    "    'temperature_min': float(temperature_min),\n",
    "    'humidity_avg': float(humidity_avg),\n",
    "    'humidity_max': float(humidity_max),\n",
    "    'humidity_min': float(humidity_min),\n",
    "    'pm25_avg': float(pm25_avg),\n",
    "    'pm25_max': float(pm25_max),\n",
    "    'air_quality_category': air_quality_category,\n",
    "    'total_sensors': int(total_sensors),\n",
    "    'total_readings': int(total_readings)\n",
    "}\n",
    "\n",
    "# Convertir a DataFrame\n",
    "kpis_df = pd.DataFrame([kpis_data])\n",
    "\n",
    "# Guardar KPIs principales (archivo Ãºnico que se sobrescribe)\n",
    "kpis_path = f\"{Config.GOLD_PATH}/kpis.parquet\"\n",
    "\n",
    "print(f\"Sobrescribiendo archivo: {kpis_path}\")\n",
    "success = minio_client.upload_dataframe_as_parquet(kpis_df, kpis_path)\n",
    "\n",
    "if success:\n",
    "    print(f\"âœ… KPIs guardados exitosamente en capa Gold\")\n",
    "    \n",
    "    # Guardar tambiÃ©n los datos completos con estadÃ­sticas por sensor\n",
    "    if 'sensor_stats' in locals():\n",
    "        sensor_stats_path = f\"{Config.GOLD_PATH}/sensor_statistics.parquet\"\n",
    "        stats_success = minio_client.upload_dataframe_as_parquet(sensor_stats, sensor_stats_path)\n",
    "        if stats_success:\n",
    "            print(f\"âœ… EstadÃ­sticas por sensor guardadas: {sensor_stats_path}\")\n",
    "    \n",
    "    # Crear log de ejecuciÃ³n (archivo Ãºnico que se sobrescribe)\n",
    "    notebook_marker = {\n",
    "        'notebook': 'gold_kpis_analysis',\n",
    "        'execution_time': timestamp.isoformat(),\n",
    "        'kpis_generated': len(kpis_data) - 2,  # Excluyendo timestamp y generation_time\n",
    "        'output_files': ['kpis.parquet', 'sensor_statistics.parquet'] if 'sensor_stats' in locals() else ['kpis.parquet'],\n",
    "        'temperature_avg': float(temperature_avg),\n",
    "        'air_quality': air_quality_category,\n",
    "        'total_sensors': int(total_sensors),\n",
    "        'status': 'completed'\n",
    "    }\n",
    "    \n",
    "    log_df = pd.DataFrame([notebook_marker])\n",
    "    log_path = f\"{Config.GOLD_PATH}/execution_log.parquet\"\n",
    "    \n",
    "    # Sobrescribir log de ejecuciÃ³n\n",
    "    minio_client.upload_dataframe_as_parquet(log_df, log_path)\n",
    "    \n",
    "    # Mostrar archivos en Gold\n",
    "    gold_files = minio_client.list_objects(Config.GOLD_PATH)\n",
    "    \n",
    "    print(\"\\n=== PROCESO COMPLETADO ===\")\n",
    "    print(f\"ğŸ“Š KPIs generados: {len(kpis_data) - 2}\")\n",
    "    print(f\"ğŸ·ï¸  Archivos en Gold: {len(gold_files)}\")\n",
    "    print(f\"ğŸ“ˆ Temperatura promedio: {temperature_avg:.2f}Â°C\")\n",
    "    print(f\"ğŸŒ¡ï¸  Calidad del aire: {air_quality_category}\")\n",
    "    print(f\"ğŸ“¡ Total sensores: {total_sensors}\")\n",
    "    print(f\"ğŸ“ Log de ejecuciÃ³n actualizado\")\n",
    "    \n",
    "    print(\"\\nğŸ‰ AnÃ¡lisis de KPIs finalizado exitosamente!\")\n",
    "    print(\"\\nğŸ“ˆ Los KPIs han sido generados y estÃ¡n disponibles en:\")\n",
    "    print(f\"   â€¢ Capa Gold de MinIO: {Config.GOLD_PATH}\")\n",
    "    print(f\"   â€¢ Archivo principal: kpis.parquet\")\n",
    "    print(f\"   â€¢ EstadÃ­sticas por sensor: sensor_statistics.parquet\")\n",
    "    print(\"\\nğŸ”„ Este anÃ¡lisis se ejecuta automÃ¡ticamente segÃºn la programaciÃ³n del ETL\")\n",
    "    print(\"ğŸ“Š Los KPIs se actualizan con cada nuevo lote de datos procesado\")\n",
    "    print(\"\\nâœ¨ Â¡Datos listos para consumo por otros mÃ³dulos del sistema!\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ Error al guardar KPIs en capa Gold\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
