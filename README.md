# Sistema ETL de Datos de Sensores

Este proyecto implementa un pipeline ETL completo para datos de sensores utilizando arquitectura de capas Bronze, Silver y Gold con MinIO como data lake y PySpark para procesamiento.

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚    â”‚  Bronze Layer   â”‚    â”‚  Silver Layer   â”‚    â”‚   Gold Layer    â”‚
â”‚   (Fuente)      â”‚â”€â”€â”€â–¶â”‚  (Raw Data)     â”‚â”€â”€â”€â–¶â”‚ (Clean Data)    â”‚â”€â”€â”€â–¶â”‚    (KPIs)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚                        â”‚
                                â–¼                        â–¼                        â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚     MinIO       â”‚    â”‚    PySpark      â”‚    â”‚   Dashboard     â”‚
                        â”‚  Data Storage   â”‚    â”‚   Processing    â”‚    â”‚   & Exports     â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Componentes

### Capas de Datos
- **Bronze**: Datos crudos extraÃ­dos de PostgreSQL
- **Silver**: Datos limpios y transformados con PySpark
- **Gold**: KPIs y mÃ©tricas para consumo

### Servicios
- **PostgreSQL**: Base de datos fuente con tabla `sensor_readings`
- **MinIO**: Data Lake compatible con S3
- **ClickHouse**: OLAP para anÃ¡lisis (opcional)
- **Grafana**: VisualizaciÃ³n y dashboards
- **Kafka**: Streaming de datos (opcional)

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Clonar y configurar el entorno

```bash
# Navegar al directorio del proyecto
cd proyecto_estacion

# Crear red Docker (opcional)
docker network create estacion-network
```

### 2. Configurar variables de entorno

El archivo `.env` ya estÃ¡ configurado con valores por defecto. Modifica segÃºn sea necesario:

```env
# Base de datos
DB_HOST=localhost
DB_PORT=5432
DB_NAME=postgres
DB_USER=postgres
DB_PASSWORD=postgres

# MinIO
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
```

### 3. Levantar los servicios

```bash
# Iniciar todos los servicios
docker-compose up -d

# Verificar que los servicios estÃ©n ejecutÃ¡ndose
docker-compose ps
```

### 4. Verificar conexiones

```bash
# Probar conexiones del sistema ETL
cd etl
python manage.py test
```

## ğŸ”§ Uso del Sistema

### Comandos Principales

```bash
# Ver estado del sistema
python manage.py status

# Carga inicial de datos (primera vez)
python manage.py initial-load

# ActualizaciÃ³n incremental
python manage.py incremental

# Pipeline completo
python manage.py full-pipeline

# Exportar KPIs
python manage.py export-kpis

# Listar archivos en data lake
python manage.py list-files

# Limpiar datos antiguos
python manage.py cleanup
```

### EjecuciÃ³n AutomÃ¡tica

El sistema incluye un scheduler que ejecuta automÃ¡ticamente:
- **ETL incremental**: Cada 30 minutos (configurable)
- **Pipeline completo**: Diariamente a las 2:00 AM
- **Limpieza**: Semanalmente los domingos a las 3:00 AM
- **Health check**: Cada hora

```bash
# Iniciar scheduler
python scheduler.py
```

## ğŸ“Š Notebooks de AnÃ¡lisis

### Silver Layer - Limpieza de Datos
- **Archivo**: `notebooks/silver_data_cleaning.ipynb`
- **DescripciÃ³n**: Limpieza y transformaciÃ³n con PySpark
- **Funciones**: EliminaciÃ³n de duplicados, validaciÃ³n, imputaciÃ³n

### Gold Layer - AnÃ¡lisis de KPIs
- **Archivo**: `notebooks/gold_kpis_analysis.ipynb`
- **DescripciÃ³n**: GeneraciÃ³n de KPIs y visualizaciones
- **Funciones**: MÃ©tricas, alertas, dashboards, exportaciÃ³n

## ğŸ—ƒï¸ Estructura de Datos

### Tabla de Origen (sensor_readings)
```sql
CREATE TABLE sensor_readings (
    id SERIAL PRIMARY KEY,
    sensor_id VARCHAR(50) NOT NULL,
    temperature DECIMAL(5,2),
    humidity DECIMAL(5,2),
    pressure DECIMAL(7,2),
    timestamp TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    location VARCHAR(100),
    status VARCHAR(20) DEFAULT 'active'
);
```

### Capas de MinIO
- `bronze/sensor_data/`: Datos crudos por lotes
- `silver/sensor_data/`: Datos limpios consolidados
- `gold/sensor_kpis/`: KPIs y mÃ©tricas
- `gold/exports/`: Archivos para consumo externo

## ğŸ“ˆ KPIs Generados

### Generales
- Total de lecturas procesadas
- NÃºmero de sensores activos
- Promedios globales (temperatura, humedad, presiÃ³n)

### Por Sensor
- EstadÃ­sticas por sensor individual
- Calidad de datos por sensor
- DetecciÃ³n de anomalÃ­as

### Por UbicaciÃ³n
- Condiciones ambientales por zona
- Ãndices de confort
- DistribuciÃ³n de sensores

### Calidad de Datos
- PuntuaciÃ³n de completitud
- Tasa de anomalÃ­as
- Registros de alta calidad

### Alertas
- Temperaturas extremas
- Humedad fuera de rango
- PresiÃ³n anÃ³mala

## ğŸŒ Acceso a Interfaces Web

- **MinIO Console**: http://localhost:9090
  - Usuario: `minioadmin` / ContraseÃ±a: `minioadmin`
- **Grafana**: http://localhost:3000
  - Usuario: `admin` / ContraseÃ±a: `admin`
- **ClickHouse**: http://localhost:8123

## ğŸ”„ Flujo de Procesamiento

1. **ExtracciÃ³n (Bronze)**:
   - ConexiÃ³n a PostgreSQL
   - ExtracciÃ³n en lotes configurables
   - Almacenamiento en MinIO como Parquet

2. **TransformaciÃ³n (Silver)**:
   - Carga de datos Bronze
   - Limpieza con PySpark:
     - EliminaciÃ³n de duplicados
     - ValidaciÃ³n de rangos
     - ImputaciÃ³n de valores faltantes
     - Enriquecimiento de datos
   - Almacenamiento de datos limpios

3. **AgregaciÃ³n (Gold)**:
   - Procesamiento de datos Silver
   - GeneraciÃ³n de KPIs
   - ExportaciÃ³n para consumo

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Cambiar IP de Base de Datos
Modifica el archivo `.env`:
```env
DB_HOST=nueva.ip.de.database
```

### Ajustar TamaÃ±o de Lotes
```env
BATCH_SIZE=2000
```

### Cambiar Intervalo de Procesamiento
```env
PROCESSING_INTERVAL_MINUTES=15
```

### ConfiguraciÃ³n de Spark
```env
SPARK_DRIVER_MEMORY=4g
SPARK_EXECUTOR_MEMORY=4g
SPARK_EXECUTOR_CORES=4
```

## ğŸ› ResoluciÃ³n de Problemas

### Error de ConexiÃ³n a PostgreSQL
1. Verificar que el servicio estÃ© ejecutÃ¡ndose
2. Comprobar credenciales en `.env`
3. Verificar conectividad de red

### Error de MinIO
1. Verificar que el servicio estÃ© activo: `docker-compose ps`
2. Comprobar acceso web en http://localhost:9090
3. Verificar permisos de bucket

### Error en PySpark
1. Verificar memoria disponible
2. Ajustar configuraciÃ³n en `.env`
3. Revisar logs en `logs/etl.log`

### Sin Datos en Bronze
```bash
# Ejecutar carga inicial
python manage.py initial-load
```

## ğŸ“ Logs

Los logs del sistema se almacenan en:
- `logs/etl.log`: Log principal del ETL
- Docker logs: `docker-compose logs etl-service`

## ğŸ¤ Consumo por Otros MÃ³dulos

Los KPIs se exportan automÃ¡ticamente en formato Parquet y estÃ¡n disponibles para consumo:

```python
# Ejemplo de consumo
from etl.utils import MinIOClient
from etl.config import Config

minio_client = MinIOClient()
kpis_df = minio_client.download_parquet_as_dataframe(
    f"{Config.GOLD_PATH}/exports/latest_kpis.parquet"
)
```

## ğŸ“ Soporte

Para soporte tÃ©cnico o preguntas sobre el sistema:
1. Revisar logs en `logs/etl.log`
2. Ejecutar `python manage.py status` para diagnÃ³stico
3. Consultar notebooks para ejemplos de uso