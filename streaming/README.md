# üîÑ Sistema de Streaming en Tiempo Real

Sistema de procesamiento de datos de sensores en streaming:
- **PostgreSQL** ‚Üí **Kafka** ‚Üí **ClickHouse** ‚Üí **Grafana**

## üìã Arquitectura

```
PostgreSQL (BD Real)          PostgreSQL (Simulado)
     ‚Üì                              ‚Üì
Producer Real                  Producer Simulado
     ‚Üì                              ‚Üì
         ‚Üí Kafka (streaming) ‚Üê
                  ‚Üì
         Consumer ClickHouse
                  ‚Üì
            ClickHouse (BD)
                  ‚Üì
              Grafana (Visualizaci√≥n)
```

## üöÄ Componentes

### 1. **kafka_producer_simulated.py**
Genera datos simulados de sensores para pruebas.

**Uso:**
```bash
python streaming/kafka_producer_simulated.py
```

**Caracter√≠sticas:**
- 3 sensores simulados
- Datos realistas (temperatura, humedad, presi√≥n, PM2.5, luz)
- Env√≠a datos cada 10 segundos
- Ideal para desarrollo y pruebas

### 2. **kafka_producer_real.py**
Lee datos reales de PostgreSQL y los env√≠a a Kafka.

**Uso:**
```bash
python streaming/kafka_producer_real.py
```

**Caracter√≠sticas:**
- Conecta a PostgreSQL
- Lee datos incrementales (solo nuevos registros)
- Guarda checkpoint en `last_kafka_timestamp.txt`
- Env√≠a datos cada 10 segundos
- Para uso en producci√≥n

**Requiere:**
- PostgreSQL ejecut√°ndose
- Tabla `sensor_readings` con datos

### 3. **kafka_consumer_clickhouse.py**
Consumer que recibe datos de Kafka y los inserta en ClickHouse.

**Uso:**
```bash
python streaming/kafka_consumer_clickhouse.py
```

**Caracter√≠sticas:**
- Conecta a Kafka
- Inserta en ClickHouse tabla `sensor_streaming`
- Crea la tabla autom√°ticamente
- Procesa hasta 100 mensajes por lote
- Logging detallado

**Requiere:**
- ClickHouse ejecut√°ndose
- Kafka ejecut√°ndose

## üìä Flujo de Ejecuci√≥n

### Para Pruebas (con datos simulados):

1. **Terminal 1**: Iniciar producer simulado
```bash
python streaming/kafka_producer_simulated.py
```

2. **Terminal 2**: Iniciar consumer ClickHouse
```bash
python streaming/kafka_consumer_clickhouse.py
```

3. **Grafana**: Acceder a http://localhost:3000
   - Usuario: admin
   - Contrase√±a: admin

### Para Producci√≥n (con datos reales):

1. **Terminal 1**: Asegurar que PostgreSQL tiene datos
```bash
python manage.py incremental
```

2. **Terminal 1**: Iniciar producer real
```bash
python streaming/kafka_producer_real.py
```

3. **Terminal 2**: Iniciar consumer ClickHouse
```bash
python streaming/kafka_consumer_clickhouse.py
```

4. **Grafana**: Crear dashboard con tabla `sensor_streaming`

## üîß Configuraci√≥n

### Kafka
- Host: `localhost:9092`
- Topic: `sensor_data_streaming`
- Consumer Group: `clickhouse_consumer`

### ClickHouse
- Host: `localhost:8123`
- Base de datos: `meteo`
- Tabla: `sensor_streaming`
- Usuario: `default`
- Contrase√±a: `clickhouse`

### PostgreSQL
- Host: `localhost`
- Puerto: `5432`
- Base de datos: `proyecto_estacion`
- Usuario: `proyecto_user`
- Contrase√±a: `proyecto_pass`

## üìà Queries √ötiles en ClickHouse

### Ver √∫ltimos datos
```sql
SELECT * FROM sensor_streaming 
ORDER BY timestamp DESC 
LIMIT 100;
```

### Datos por sensor
```sql
SELECT 
    sensor_id,
    COUNT(*) as total,
    AVG(temperature) as temp_promedio,
    AVG(humidity) as humidity_promedio
FROM sensor_streaming
GROUP BY sensor_id;
```

### Datos √∫ltimos 10 minutos
```sql
SELECT *
FROM sensor_streaming
WHERE timestamp > now() - INTERVAL 10 MINUTE
ORDER BY timestamp DESC;
```

### Alertas de PM2.5 alto
```sql
SELECT *
FROM sensor_streaming
WHERE pm25 > 100
ORDER BY timestamp DESC;
```

## üì¶ Dependencias

```
kafka-python
psycopg2
clickhouse-driver
```

**Instalar:**
```bash
pip install kafka-python psycopg2 clickhouse-driver
```

## ‚ö° Tips

1. **Monitoreo en tiempo real**: Abre dos terminales
   - Una con producer
   - Otra con consumer
   - Vigila los logs

2. **Datos hist√≥ricos**: El producer real se ajusta con `last_kafka_timestamp.txt`

3. **Simulado vs Real**: Cambiar de simulado a real solo requiere cambiar el producer

4. **Debugging**: Los logs muestran timestamps y detalles de cada operaci√≥n

## üêõ Soluci√≥n de Problemas

### Error: "No se puede conectar a Kafka"
- Verifica: `docker-compose ps` (Kafka debe estar corriendo)

### Error: "No se puede conectar a ClickHouse"
- Verifica: `docker-compose ps` (ClickHouse debe estar corriendo)

### Error: "No se puede conectar a PostgreSQL"
- Verifica: `docker ps | grep postgres` (PostgreSQL debe estar corriendo)

### No hay datos en ClickHouse
- Verifica que el consumer est√© ejecut√°ndose
- Verifica que el producer est√© enviando datos a Kafka
- Revisa los logs para errores

## üìû Pr√≥ximos Pasos

1. Crear dashboard en Grafana con los datos en tiempo real
2. Configurar alertas basadas en umbrales de PM2.5
3. Crear agregaciones en ClickHouse para reportes hist√≥ricos
